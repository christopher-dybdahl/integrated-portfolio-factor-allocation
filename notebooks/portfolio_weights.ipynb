{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e95390d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdfddd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path.cwd().parent / \"data\"\n",
    "df_factors = pd.read_csv(data_dir / \"factors.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d00ca521",
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_rename = {\n",
    "    \"ret_geo\": \"W\",\n",
    "    \"vol_36m\": \"L\",\n",
    "    \"value\": \"V\",\n",
    "    \"investment\": \"C\",\n",
    "    \"profitability\": \"R\",\n",
    "}\n",
    "df_factors = df_factors.rename(columns=factor_rename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b49fc0",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d3620ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _yearly_z_score(df, cols, date_col=\"date\"):\n",
    "    years = df[date_col]\n",
    "\n",
    "    for c in cols:\n",
    "        if c not in df.columns:\n",
    "            raise KeyError(f\"{c} not in DataFrame\")\n",
    "\n",
    "        def _z(s):\n",
    "            std = s.std(ddof=0)\n",
    "            if std == 0 or np.isnan(std):\n",
    "                return pd.Series(0.0, index=s.index)\n",
    "            return (s - s.mean()) / std\n",
    "\n",
    "        df[\"z_\" + c] = df.groupby(years)[c].transform(_z)\n",
    "    return df\n",
    "\n",
    "\n",
    "def _yearly_rank_score(df, cols, date_col=\"date\"):\n",
    "    years = df[date_col]\n",
    "\n",
    "    for c in cols:\n",
    "        if c not in df.columns:\n",
    "            raise KeyError(f\"{c} not in DataFrame\")\n",
    "\n",
    "        def _rank01(s):\n",
    "            n = s.notna().sum()\n",
    "            if n <= 1:\n",
    "                return pd.Series(0.0, index=s.index)\n",
    "            r = s.rank(method=\"average\")\n",
    "            return (r - 1) / (n - 1)\n",
    "\n",
    "        df[\"rank_\" + c] = df.groupby(years)[c].transform(_rank01)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Function to create z- or rank-scored factors\n",
    "def yearly_score(df, cols, method, date_col=\"date\"):\n",
    "    if date_col not in df.columns:\n",
    "        raise KeyError(f\"{date_col} not in DataFrame\")\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    if method == \"z\":\n",
    "        return _yearly_z_score(df, cols, date_col=date_col)\n",
    "    elif method == \"rank\":\n",
    "        return _yearly_rank_score(df, cols, date_col=date_col)\n",
    "    else:\n",
    "        raise ValueError(\"method must be 'z' or 'rank'\")\n",
    "\n",
    "\n",
    "# Function to create an average factor for the integrated approach\n",
    "def append_avg_score(df, cols, method):\n",
    "    if method == \"z\":\n",
    "        prefix = \"z_\"\n",
    "    elif method == \"rank\":\n",
    "        prefix = \"rank_\"\n",
    "    else:\n",
    "        raise ValueError(\"method must be 'z' or 'rank'\")\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    score_cols = [prefix + c for c in cols]\n",
    "    for c in score_cols:\n",
    "        if c not in df.columns:\n",
    "            raise KeyError(f\"{c} not in DataFrame\")\n",
    "\n",
    "    df[prefix + \"int\"] = df[score_cols].mean(axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Function to create TER and DEC portfolio weights for each factor provided\n",
    "def percentile_portfolio_weights(\n",
    "    df, cols, method, p, mkt_cap_col=\"market_cap\", date_col=\"date\"\n",
    "):\n",
    "    if method == \"z\":\n",
    "        prefix = \"z_\"\n",
    "    elif method == \"rank\":\n",
    "        prefix = \"rank_\"\n",
    "    else:\n",
    "        raise ValueError(\"method must be 'z' or 'rank'\")\n",
    "\n",
    "    if mkt_cap_col not in df.columns:\n",
    "        raise KeyError(f\"{mkt_cap_col} not in DataFrame\")\n",
    "\n",
    "    if date_col not in df.columns:\n",
    "        raise KeyError(f\"{date_col} not in DataFrame\")\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    years = df[date_col]\n",
    "\n",
    "    df_weights = df[[date_col]].copy()\n",
    "\n",
    "    for c in cols:\n",
    "        score_col = prefix + c\n",
    "        if score_col not in df.columns:\n",
    "            raise KeyError(f\"{score_col} not in DataFrame\")\n",
    "\n",
    "        # Calculate quantile threshold per year\n",
    "        thresholds = df.groupby(years)[score_col].transform(lambda x: x.quantile(1 - p))\n",
    "\n",
    "        # Identify companies in top percentile\n",
    "        mask = (df[score_col] >= thresholds) & (df[score_col].notna())\n",
    "\n",
    "        # Calculate total market cap of selected companies per year\n",
    "        masked_mkt_cap = df[mkt_cap_col].where(mask, 0.0)\n",
    "        yearly_total_cap = masked_mkt_cap.groupby(years).transform(\"sum\")\n",
    "\n",
    "        # Calculate weights\n",
    "        weights = masked_mkt_cap / yearly_total_cap\n",
    "        df_weights[f\"weight_{score_col}\"] = weights.fillna(0.0)\n",
    "\n",
    "    return df_weights\n",
    "\n",
    "\n",
    "# Function to create the BW weights for each factor provided\n",
    "def bw_portfolio_weights(\n",
    "    df,\n",
    "    cols,\n",
    "    method,\n",
    "    n_subportfolios,\n",
    "    high_multiplier,\n",
    "    increment,\n",
    "    multiple_power=1,\n",
    "    mkt_cap_col=\"market_cap\",\n",
    "    date_col=\"date\",\n",
    "):\n",
    "    if method == \"z\":\n",
    "        prefix = \"z_\"\n",
    "    elif method == \"rank\":\n",
    "        prefix = \"rank_\"\n",
    "    else:\n",
    "        raise ValueError(\"method must be 'z' or 'rank'\")\n",
    "\n",
    "    if mkt_cap_col not in df.columns:\n",
    "        raise KeyError(f\"{mkt_cap_col} not in DataFrame\")\n",
    "\n",
    "    if date_col not in df.columns:\n",
    "        raise KeyError(f\"{date_col} not in DataFrame\")\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    years = df[date_col]\n",
    "\n",
    "    df_weights = df[[date_col]].copy()\n",
    "\n",
    "    for c in cols:\n",
    "        score_col = prefix + c\n",
    "        if score_col not in df.columns:\n",
    "            raise KeyError(f\"{score_col} not in DataFrame\")\n",
    "\n",
    "        # Helper to calculate buckets safely\n",
    "        def _get_buckets(x):\n",
    "            try:\n",
    "                return pd.qcut(x, n_subportfolios, labels=False, duplicates=\"drop\")\n",
    "            except ValueError:\n",
    "                return pd.Series(np.nan, index=x.index)\n",
    "\n",
    "        # Create temporary bucket column\n",
    "        bucket_col = f\"_temp_bucket_{c}\"\n",
    "        df[bucket_col] = df.groupby(years)[score_col].transform(_get_buckets)\n",
    "\n",
    "        # Calculate total market cap per bucket per year\n",
    "        bucket_caps = df.groupby([years, bucket_col])[mkt_cap_col].transform(\"sum\")\n",
    "\n",
    "        # Calculate number of buckets per year to ensure equal size partition\n",
    "        max_bucket = df.groupby(years)[bucket_col].transform(\"max\")\n",
    "        n_buckets = max_bucket + 1\n",
    "\n",
    "        # Base weights (equal size buckets)\n",
    "        base_weights = (df[mkt_cap_col] / bucket_caps) * (1.0 / n_buckets)\n",
    "\n",
    "        # Multipliers\n",
    "        # high_multiplier for max_bucket, decreasing by increment\n",
    "        multipliers = high_multiplier - (max_bucket - df[bucket_col]) * increment\n",
    "\n",
    "        # Final weights\n",
    "        df_weights[f\"weight_{score_col}\"] = (\n",
    "            base_weights * (multipliers**multiple_power)\n",
    "        ).fillna(0.0)\n",
    "\n",
    "        # Cleanup\n",
    "        df.drop(columns=[bucket_col], inplace=True)\n",
    "\n",
    "    return df_weights\n",
    "\n",
    "\n",
    "# Function to create the mixed portfolio weights\n",
    "def factor_adjusted_weights(df, cols, factor_weights, method):\n",
    "    if method == \"z\":\n",
    "        prefix = \"z_\"\n",
    "    elif method == \"rank\":\n",
    "        prefix = \"rank_\"\n",
    "    else:\n",
    "        raise ValueError(\"method must be 'z' or 'rank'\")\n",
    "\n",
    "    if len(cols) != len(factor_weights):\n",
    "        raise ValueError(\"cols and factor_weights must have the same length\")\n",
    "\n",
    "    weight_cols = [f\"weight_{prefix}{c}\" for c in cols]\n",
    "    for c in weight_cols:\n",
    "        if c not in df.columns:\n",
    "            raise KeyError(f\"{c} not in DataFrame\")\n",
    "\n",
    "    weighted_sum = 0\n",
    "    for col, weight in zip(weight_cols, factor_weights):\n",
    "        weighted_sum += df[col] * weight\n",
    "\n",
    "    return weighted_sum\n",
    "\n",
    "\n",
    "# TODO: Create the TE portfolio weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "43ece08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_combs = [[\"V\", \"W\"]]\n",
    "p_list = [1 / 3, 1 / 10]\n",
    "percentile_suffixes = [\"_ter\", \"_dec\"]\n",
    "method_percentile = \"rank\"\n",
    "method_bw = \"z\"\n",
    "int_factor_name = \"int\"\n",
    "n_subportfolios = 20\n",
    "high_multiplier = 1.95\n",
    "increment = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "659a3e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_COLS = [\"PERMNO\", \"date\", \"tic\", \"conm\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ea5b8ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for factor_comb in factor_combs:\n",
    "    # Initialize df_weights with ID columns\n",
    "    df_weights = df_factors[ID_COLS].copy()\n",
    "\n",
    "    ### TER & DEC ###\n",
    "    # Compute percentile weight scores\n",
    "    df_score = yearly_score(\n",
    "        df_factors,\n",
    "        factor_comb,\n",
    "        method_percentile,\n",
    "    )\n",
    "\n",
    "    # Compute integrated score\n",
    "    df_score = append_avg_score(df_score, factor_comb, method_percentile)\n",
    "\n",
    "    factor_weights = [1 / len(factor_comb)] * len(factor_comb)\n",
    "\n",
    "    # Define suffixes for the p_list values\n",
    "    for p, suffix in zip(p_list, percentile_suffixes):\n",
    "        # Compute integrated percentile weights\n",
    "        df_w = percentile_portfolio_weights(\n",
    "            df_score,\n",
    "            [int_factor_name],\n",
    "            method_percentile,\n",
    "            p,\n",
    "        )\n",
    "        df_w.columns = [\"date\", \"_\".join(factor_comb) + \"_int\"]\n",
    "\n",
    "        # Compute temporary factor percentile weights for mixed calculation\n",
    "        temp = percentile_portfolio_weights(\n",
    "            df_score,\n",
    "            factor_comb,\n",
    "            method_percentile,\n",
    "            p,\n",
    "        )\n",
    "\n",
    "        # Compute mixed percentile weights\n",
    "        df_w[\"_\".join(factor_comb) + \"_mix\"] = factor_adjusted_weights(\n",
    "            temp, factor_comb, factor_weights, method_percentile\n",
    "        )\n",
    "\n",
    "        # Rename columns with suffix and drop date (already in df_weights)\n",
    "        df_w = df_w.drop(columns=[\"date\"]).add_suffix(suffix)\n",
    "\n",
    "        # Concatenate to main df\n",
    "        df_weights = pd.concat([df_weights, df_w], axis=1)\n",
    "\n",
    "    ### BW ###\n",
    "\n",
    "    # Compute BW weight scores\n",
    "    df_score = yearly_score(\n",
    "        df_factors,\n",
    "        factor_comb,\n",
    "        method_bw,\n",
    "    )\n",
    "\n",
    "    # Compute integrated score\n",
    "    df_score = append_avg_score(df_score, factor_comb, method_bw)\n",
    "\n",
    "    # Compute integrated BW weights\n",
    "    df_w = bw_portfolio_weights(\n",
    "        df_score,\n",
    "        [int_factor_name],\n",
    "        method_bw,\n",
    "        n_subportfolios,\n",
    "        high_multiplier,\n",
    "        increment,\n",
    "    )\n",
    "    df_w.columns = [\"date\", \"_\".join(factor_comb) + \"_int\"]\n",
    "\n",
    "    # Compute temporary factor BW weights for mixed calculation\n",
    "    temp = bw_portfolio_weights(\n",
    "        df_score,\n",
    "        factor_comb,\n",
    "        method_bw,\n",
    "        n_subportfolios,\n",
    "        high_multiplier,\n",
    "        increment,\n",
    "    )\n",
    "\n",
    "    # Compute mixed BW weights\n",
    "    df_w[\"_\".join(factor_comb) + \"_mix\"] = factor_adjusted_weights(\n",
    "        temp, factor_comb, factor_weights, method_bw\n",
    "    )\n",
    "\n",
    "    # Rename columns with suffix and drop date\n",
    "    df_w = df_w.drop(columns=[\"date\"]).add_suffix(\"_bw\")\n",
    "\n",
    "    # Concatenate to main df\n",
    "    df_weights = pd.concat([df_weights, df_w], axis=1)\n",
    "\n",
    "    df_weights.to_csv(\n",
    "        data_dir / \"strategies\" / f\"{'_'.join(factor_comb)}.csv\", index=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bc8258f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: All portfolio weights sum to 1.0 for each year.\n"
     ]
    }
   ],
   "source": [
    "# Verify that weights sum to 1 per year\n",
    "weight_cols = [c for c in df_weights.columns if \"weight_\" in c]\n",
    "yearly_sums = df_weights.groupby(\"date\")[weight_cols].sum()\n",
    "\n",
    "# Check if all sums are approximately 1\n",
    "if np.allclose(yearly_sums, 1.0):\n",
    "    print(\"Success: All portfolio weights sum to 1.0 for each year.\")\n",
    "else:\n",
    "    print(\"Failure: Some portfolio weights do not sum to 1.0.\")\n",
    "    # Show first few failures\n",
    "    failures = yearly_sums[~np.isclose(yearly_sums, 1.0).all(axis=1)]\n",
    "    print(failures.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "integrated-portfolio-factor-allocation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
